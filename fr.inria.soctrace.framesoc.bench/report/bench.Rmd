---
title: "Framesoc Bench"
author: "Generoso Pagano"
date: "01/08/2015"
output:
  html_document: default
  pdf_document: default
---

```{r, echo=FALSE}
## RUN THIS BEFORE ALL

library("plyr")                                                                                                                                              
library("ggplot2")   

## Summarizes data.
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    require(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

# utility to get trace data
get_trace <- function(data, s) {
  df <- data.frame(data)
  df <- df[df$size==s,]
  return(df)
}

```

# Intro

## Summary
Framesoc infrastructure benchmark, concerning trace import times and event reading times.

## Vocabulary
* Parameter: something influencing the behavior of the system.
* Factor: parameter you decide to variate during experiment.
* Level: value given to a factor.
* Metric: what we want to measure

# Environment

Hard disk details, obtained with hdparm.

```
[generoso@generosohp ~]$ sudo hdparm -i /dev/sdb1

/dev/sdb1:

 Model=Hitachi HDS721010CLA630, FwRev=JP4OA41A, SerialNo=JP2940N03MSP5V
 Config={ HardSect NotMFM HdSw>15uSec Fixed DTR>10Mbs }
 RawCHS=16383/16/63, TrkSize=0, SectSize=0, ECCbytes=56
 BuffType=DualPortCache, BuffSize=29999kB, MaxMultSect=16, MultSect=16
 CurCHS=16383/16/63, CurSects=16514064, LBA=yes, LBAsects=1953525168
 IORDY=on/off, tPIO={min:120,w/IORDY:120}, tDMA={min:120,rec:120}
 PIO modes:  pio0 pio1 pio2 pio3 pio4 
 DMA modes:  mdma0 mdma1 mdma2 
 UDMA modes: udma0 udma1 udma2 udma3 udma4 udma5 *udma6 
 AdvancedPM=no WriteCache=enabled
 Drive conforms to: unknown:  ATA/ATAPI-2,3,4,5,6,7

```

System details, obtained with custom script.

```
[generoso@generosohp ~]$ ./read_configuration.sh 
# OS details
Linux generosohp.imag.fr 3.9.10-100.fc17.x86_64 #1 SMP Sun Jul 14 01:31:27 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
# HW details
Number of CPUs: 12
CPU information (all cpus are equal):
- model name : Intel(R) Xeon(R) CPU E5-1660 0 @ 3.30GHz
- cache size : 15360 KB
- hyperthreading : active
Scaling governor: performance
RAM: 16360588 kB
```

# Benchmark
    
## Trace Import

### Description

* Factors: 
    + Trace size: measured in # of events, directly translatable in the DB size (MB)
    + Indexing: boolean (are we indexing on time stamp or not?)
* Levels
    + Trace size:
        - small: 1 Mevent (66.3 MB without index, 81.2 MB with index)
        - medium: 10 Mevent (692.6 MB without index, 843.9 MB with index)
        - big: 100 Mevent (7.5 GB without index, 9.3 GB with index)
    + Indexing:
        - true
        - false
* Metric:
    + Import time
* Other parameters: 
    + fake traces created with the tool Temictli (available on https://github.com/soctrace-inria/framesoc.various)
    + the Temictli configuration file used is provided in this archive (./conf/temictli_bench.conf).
    + all the traces have 2 event parameters for each event (this has been chosen as an average value over many trace formats)
* Experiments:
    + small traces: 30 repetitions
    + medium traces: 10 repetitions
    + big traces: 5 repetitions
    + NOTE: as we will see below this number of repetition is largely enough to ensure very small confidence intervals.

### Analysis

Import time given the number of events and the indexing property.

```{r, echo=FALSE}                                                                                                                                              
# read data
df <- read.csv("../results/temictli_bench.log")
# aggregate
re <- summarySE(df, measurevar="time", groupvars=c("size", "index"))
# plot                                                                                                                                                             
ggplot(re, aes(x=size, y=time, colour=index)) +                 
geom_line() +
geom_errorbar(aes(ymin=time-se, ymax=time+se), width=.1) +                                                                                               
geom_point() +                                                                                                                                                 
scale_y_continuous(name="time (s)") +                                                                                                                          
scale_x_continuous(name="# of events")        
```

Text representation of the above plot.

```{r, echo=FALSE}
re
```

## Trace reading

### Description

Note: for factors and levels already seen above (e.g. trace size), we omit the description,
since it is the same.

* Factors: 
    + Trace size
    + Indexing
    + Reading parameters: boolean
    + Reading interval: the number of events per interval (all events, 100k events, ...)
* Levels
    + Trace size:
        - small
        - medium
        - big
    + Indexing and Reading parameters:
        - true
        - false
    + Interval
        - all events, labelled as interval=0 (only small and medium traces)
        - 100k events, labelled as interval=100000 (chosen as best compromise between speed and UI interactivity)
* Metric:
    + Total read time
    + Interval read time
* Other parameters: 
    + fake traces created above
    + the program used for reading (fr.inria.soctrace.framesoc.bench) is available on github:
    (https://github.com/soctrace-inria/framesoc.various)
* Experiments:
    + small traces: 30+ repetitions
    + medium traces: 10+ repetitions
    + big traces: only partial execution, to have the time to read an interval. No tests without interval (all events) because of memory limits.
    + NOTE: as we will see below this number of repetition is largely enough to ensure very small confidence intervals.

### Analysis

```{r, echo=FALSE}
# prepare data summaries
df <- read.csv("../results/reader_second.log")

# total time summary
dftime <- summarySE(df, measurevar="total_time", groupvars=c("size", "index", "param", "interval"))

# interval summary
dfinterval <- summarySE(df, measurevar="interval_time", groupvars=c("size", "index", "param", "interval"))

# read all, par, index
readall <- dftime[dftime$interval=='0',]
# read interval, par, index
readint <- dftime[dftime$interval=='100000',]
# read nopar, interval, index
readnopar <- dftime[dftime$param=='false',]
intervalnopar <- dfinterval[dfinterval$param=='false',]

small_readall <- get_trace(readall, 1000000)
medium_readall <- get_trace(readall, 10000000)
big_readall <- get_trace(readall, 100000000)

small_readint <- get_trace(readint, 1000000)
medium_readint <- get_trace(readint, 10000000)
big_readint <- get_trace(readint, 100000000)

small_readnopar <- get_trace(readnopar, 1000000)
medium_readnopar <- get_trace(readnopar, 10000000)
big_readnopar <- get_trace(readnopar, 100000000)

small_intervalnopar <- get_trace(intervalnopar, 1000000)
medium_intervalnopar <- get_trace(intervalnopar, 10000000)
big_intervalnopar <- get_trace(intervalnopar, 100000000)
```

#### Summarized values

##### Total time
```{r, echo=FALSE}
dftime[c(1,2,3,4,6)]
```

##### Interval time
```{r, echo=FALSE}
dfinterval[c(1,2,3,4,6)]
```

#### Total read time (no interval reading), with and without param, with and without index.

Small trace

```{r, echo=FALSE}
ggplot(data=small_readall, aes(x=index, y=total_time, fill=param)) + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=total_time-ci, ymax=total_time+ci), width=.1, position=position_dodge(.9)) +
scale_y_continuous(name="Total time (ms)")  
```

Medium trace

```{r, echo=FALSE}
ggplot(data=medium_readall, aes(x=index, y=total_time, fill=param)) + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=total_time-ci, ymax=total_time+ci), width=.1, position=position_dodge(.9)) +
scale_y_continuous(name="Total time (ms)")  
```

Big trace

Without interval (reading all), giving 10 GB of heap space to eclipse, it was impossible to run these tests

Got the following `OutOfMemoryError` error: 
      ```
      !ENTRY org.eclipse.core.jobs 4 2 2015-01-14 15:41:18.088
      !MESSAGE An internal error occurred during: "Framesoc Reader".
      !STACK 0
      java.lang.OutOfMemoryError: GC overhead limit exceeded
        at java.util.ArrayList.<init>(ArrayList.java:132)
        at java.util.ArrayList.<init>(ArrayList.java:139)
        at fr.inria.soctrace.lib.model.Event.<init>(Event.java:122)
      	at fr.inria.soctrace.lib.model.State.<init>(State.java:24)
      	at fr.inria.soctrace.lib.model.Event.createCategorizedEvent(Event.java:108)
      	at fr.inria.soctrace.lib.query.EventQuery.rebuildEvent(EventQuery.java:395)
      	at fr.inria.soctrace.lib.query.EventQuery.rebuildEvents(EventQuery.java:357)
      	at fr.inria.soctrace.lib.query.EventQuery.getList(EventQuery.java:208)
      	at fr.inria.soctrace.framesoc.bench.reading.FramesocReader.readAll(FramesocReader.java:166)
      	at fr.inria.soctrace.framesoc.bench.reading.FramesocReader.doExperiment(FramesocReader.java:147)
      	at fr.inria.soctrace.framesoc.bench.reading.FramesocReader.main(FramesocReader.java:131)
      	at fr.inria.soctrace.framesoc.bench.reading.FramesocReaderTool$1.run(FramesocReaderTool.java:20)
      	at org.eclipse.core.internal.jobs.Worker.run(Worker.java:53)
      ```


#### Total read time (interval reading), with and without param, with and without index.

Small trace

```{r, echo=FALSE}
ggplot(data=small_readint, aes(x=index, y=total_time, fill=param)) + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=total_time-ci, ymax=total_time+ci), width=.1, position=position_dodge(.9)) +
scale_y_continuous(name="Total time (ms)")  
```

Medium trace

```{r, echo=FALSE}
ggplot(data=medium_readint, aes(x=index, y=total_time, fill=param)) + geom_bar(stat="identity", position=position_dodge()) +
geom_errorbar(aes(ymin=total_time-ci, ymax=total_time+ci), width=.1, position=position_dodge(.9)) +
scale_y_continuous(name="Total time (ms)")  
```

Big trace

- with interval
    - with index
        - with param, reading an interval is about 139 seconds, for the whole trace it would take 38 hours (TABLE)
        - without param, reading an interval is 250 milliseconds, so 4 minutes for the whole trace (GANTT)
    - without index
        - with param, reading an interval is about 172 seconds, 47 h for the trace
        - without param, 61 seconds for an interval, 16 hours for the trace
        
    - NOTE: using param is SO long because there is no index on the EVENT_ID of EVENT_PARAM table. See conclusions.

#### Total read time and interval time, without param, with and without index.

Small trace

```{r, echo=FALSE}
ggplot(data=small_readnopar, aes(x=index, y=total_time, fill=factor(interval)))  + 
         geom_bar(stat="identity", position=position_dodge()) + 
         geom_errorbar(aes(ymin=total_time-ci, ymax=total_time+ci), width=.1, position=position_dodge(.9)) + 
         scale_y_continuous(name="Total time (ms)")  
```

Average time to start getting results (get an interval in the interval case)

```{r, echo=FALSE}
ggplot(data=small_intervalnopar, aes(x=index, y=interval_time, fill=factor(interval)))  + 
         geom_bar(stat="identity", position=position_dodge()) + 
         geom_errorbar(aes(ymin=interval_time-ci, ymax=interval_time+ci), width=.1, position=position_dodge(.9)) + 
         scale_y_continuous(name="Total time (ms)")  
```

Medium trace

```{r, echo=FALSE}
ggplot(data=medium_readnopar, aes(x=index, y=total_time, fill=factor(interval)))  + 
         geom_bar(stat="identity", position=position_dodge()) + 
         geom_errorbar(aes(ymin=total_time-ci, ymax=total_time+ci), width=.1, position=position_dodge(.9)) + 
         scale_y_continuous(name="Total time (ms)")  
```

Average time to start getting results (get an interval in the interval case)

```{r, echo=FALSE}
ggplot(data=medium_intervalnopar, aes(x=index, y=interval_time, fill=factor(interval)))  + 
         geom_bar(stat="identity", position=position_dodge()) + 
         geom_errorbar(aes(ymin=interval_time-ci, ymax=interval_time+ci), width=.1, position=position_dodge(.9)) + 
         scale_y_continuous(name="Total time (ms)")  
```


Big trace

- read all (interval==0): no data because of memory limits.
- with interval
    - with index
        - without param, reading an interval is ~240 milliseconds, so about 4 minutes for the whole trace (GANTT)
    - without index
        - without param, 61 seconds for an interval, 16 hours for the trace

#### Conclusion

- Having parameters (without an index on event_id in the EVENT_PARAM table) kills performance in reading.
  This is because, even if we have a temporal index to load events, we still have to search THE WHOLE EVENT_PARAM
  table to link the params to the events. For this reason an index on the event_id field of this table would solve
  the issue. However, the only use-case where parameters are loaded is the table and this kind of visualization is
  NOT intended to be used for the WHOLE trace, but only on small subsets (after analyzing with the gantt for example).
  For this reason we don't have by default this index. 
  It could be a possibility to add it.
  TODO: measure the impact on import time.
  
- Having an index on the timestamp makes sense only for interval reading. If we read all, it has no effect on reading.
  As the trace size increases, it becames absolutely necessary. 
  For example: reading the big trace using intervals and not loading parameters (GANTT) would take about 16 hours without index and only 4 minutes with the index. 

- Interval reading ([with index, without parameters] == gantt) increments total time by a factor from 3 to 2 (decreasing as the trace size increase), but we can have a first meaningful feedback in about 250 ms (first interval). Note that for big traces interval reading is compulsory, since we are limited by the memory.
